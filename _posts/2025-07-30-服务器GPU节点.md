---
title: "服务器GPU节点"
toc: true
toc_label: "文章目录"  # 自定义目录标题
toc_icon: "list-ul"   # 可选：使用Font Awesome图标
lang: zh-CN
categories:
  - Blog
tags:
  - GPU
---

## 1. 概述

- Yang Group HFNL 服务器共有`1`个`GPU`计算节点，可通过`ssh gpu/ssh node99`登录；

- `CPU`型号为`Intel(R) Xeon(R) Platinum 8358P`，主频`2600 MHz`，`64`核，`2 TB` 内存；

- `GPU`型号为`A800`,`8`块`80 GB`计算卡，驱动版本`530.30.02`。

---

## 2. 队列设置

| **队列名**       | **时间限制** | **单用户运行限制作业数** | **单用户提交限制作业数** |
|:----------------:|:-----------:|:-----------------------:|:-----------------------:|
| `gpu`           | 默认1天，最长3天         | 2                      |  4                   |

## 3. 使用方法

1. `sbatch`脚本提交任务，例如：
    示例脚本 `gpu.sh`：

    ```bash
    #!/bin/bash
    #SBATCH -J test
    #SBATCH -p gpu
    #SBATCH -N 1
    #SBATCH -n 16                                   # 需要少于64
    #SBATCH --gres=gpu:NVIDIAA800-SXM4-80GB:2       # 任务2块A800
    #SBATCH --mem=240G                              # 任务配240GB内存(根据应用调整)
    #SBATCH -o %j.log
    #SBATCH -e %j.err

    echo "SLURM_JOB_PARTITION=$SLURM_JOB_PARTITION"
    echo "SLURM_JOB_NODELIST=$SLURM_JOB_NODELIST"
    echo Time is `date`
    echo Directory is $PWD
    echo This job runs on the following nodes:
    echo $SLURM_JOB_NODELIST
    echo This job has allocated $SLURM_JOB_CPUS_PER_NODE cpu cores.

    your_gpu_command
    ```

    提交命令：`sbatch gpu.sh`
2. **为了充分利用`GPU`节点，`GPU`运行、产生的数据请存放在`/gpu_data`，自行在这个目录新建子文件夹！**
3. `CUDA ToolKit`位于`GPU`**节点目录**`/usr/local/cuda-11.6`，`/usr/local/cuda-12.1`，`/usr/local/cuda-11.6`，**不在主登录节点上**，请`ssh gpu`;
4. 作业加时联系管理员孟鑫勇。
